{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DaFFOHrvhMJJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load and clean data\n",
        "df = pd.read_csv('spam.csv', encoding='latin-1')\n",
        "df = df[['v1', 'v2']].rename(columns={'v1': 'label', 'v2': 'message'})\n",
        "df['label'] = df['label'].map({'ham': 0, 'spam': 1})\n"
      ],
      "metadata": {
        "id": "YvjgWz8gkhyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Download NLTK stopwords (default path used)\n",
        "nltk.download('stopwords')\n",
        "stemmer = PorterStemmer()\n",
        "stop_words = set(stopwords.words('english'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h35iiBCHkiBL",
        "outputId": "fa9b403e-05a6-4adb-8f11-3e3d18035d3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Text preprocessing function\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'[^a-zA-Z]', ' ', text.lower())\n",
        "    words = text.split()\n",
        "    words = [stemmer.stem(word) for word in words if word not in stop_words]\n",
        "    return ' '.join(words)\n",
        "\n",
        "df['cleaned_message'] = df['message'].apply(clean_text)\n"
      ],
      "metadata": {
        "id": "qGd-JVlIkqbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# TF-IDF vectorization\n",
        "tfidf = TfidfVectorizer(ngram_range=(1, 2), max_features=5000)\n",
        "X = tfidf.fit_transform(df['cleaned_message'])\n",
        "y = df['label']\n"
      ],
      "metadata": {
        "id": "N-kjcCAQkqi7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train/test split for traditional ML models\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n"
      ],
      "metadata": {
        "id": "dK0gFE-Qkqmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Naive Bayes\n",
        "nb = MultinomialNB()\n",
        "nb.fit(X_train, y_train)\n",
        "nb_acc = nb.score(X_test, y_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "Z2H6_B_fkqs0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression\n",
        "lr = LogisticRegression(max_iter=1000)\n",
        "lr.fit(X_train, y_train)\n",
        "lr_acc = lr.score(X_test, y_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "sSyHE7xVk553"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Support Vector Machine\n",
        "svm = SVC(kernel='linear')\n",
        "svm.fit(X_train, y_train)\n",
        "svm_acc = svm.score(X_test, y_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "rHW6d6jzk90b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization and padding for LSTM\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(df['cleaned_message'])\n",
        "sequences = tokenizer.texts_to_sequences(df['cleaned_message'])\n",
        "X_padded = pad_sequences(sequences, maxlen=100)\n",
        "\n"
      ],
      "metadata": {
        "id": "f1mQYfiTk-At"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train/test split for LSTM\n",
        "X_train_lstm, X_test_lstm, y_train_lstm, y_test_lstm = train_test_split(X_padded, y, test_size=0.2, random_state=42)\n",
        "\n"
      ],
      "metadata": {
        "id": "Qmt5ZnEdk-EF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=5000, output_dim=128, input_length=100))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X_train_lstm, y_train_lstm, epochs=16, batch_size=64, validation_split=0.1)\n",
        "lstm_acc = model.evaluate(X_test_lstm, y_test_lstm)[1]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSn-X-FPlHyj",
        "outputId": "fa9410b4-dd8b-470b-8c48-97055461b7b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 262ms/step - accuracy: 0.8767 - loss: 0.3513 - val_accuracy: 0.9619 - val_loss: 0.1298\n",
            "Epoch 2/16\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 210ms/step - accuracy: 0.9844 - loss: 0.0534 - val_accuracy: 0.9709 - val_loss: 0.0915\n",
            "Epoch 3/16\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 202ms/step - accuracy: 0.9951 - loss: 0.0234 - val_accuracy: 0.9731 - val_loss: 0.1085\n",
            "Epoch 4/16\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 246ms/step - accuracy: 0.9990 - loss: 0.0066 - val_accuracy: 0.9686 - val_loss: 0.1029\n",
            "Epoch 5/16\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 201ms/step - accuracy: 0.9991 - loss: 0.0045 - val_accuracy: 0.9686 - val_loss: 0.1078\n",
            "Epoch 6/16\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 192ms/step - accuracy: 0.9988 - loss: 0.0053 - val_accuracy: 0.9753 - val_loss: 0.1264\n",
            "Epoch 7/16\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 199ms/step - accuracy: 0.9994 - loss: 0.0029 - val_accuracy: 0.9709 - val_loss: 0.1290\n",
            "Epoch 8/16\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 210ms/step - accuracy: 0.9998 - loss: 0.0014 - val_accuracy: 0.9731 - val_loss: 0.1479\n",
            "Epoch 9/16\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 226ms/step - accuracy: 0.9999 - loss: 0.0010 - val_accuracy: 0.9731 - val_loss: 0.1743\n",
            "Epoch 10/16\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 205ms/step - accuracy: 1.0000 - loss: 5.4661e-04 - val_accuracy: 0.9709 - val_loss: 0.1684\n",
            "Epoch 11/16\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 202ms/step - accuracy: 1.0000 - loss: 4.2403e-04 - val_accuracy: 0.9686 - val_loss: 0.1731\n",
            "Epoch 12/16\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 201ms/step - accuracy: 1.0000 - loss: 3.5451e-04 - val_accuracy: 0.9753 - val_loss: 0.2054\n",
            "Epoch 13/16\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 203ms/step - accuracy: 1.0000 - loss: 1.4079e-04 - val_accuracy: 0.9709 - val_loss: 0.1854\n",
            "Epoch 14/16\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 198ms/step - accuracy: 1.0000 - loss: 2.4072e-04 - val_accuracy: 0.9753 - val_loss: 0.2061\n",
            "Epoch 15/16\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 199ms/step - accuracy: 1.0000 - loss: 1.5573e-04 - val_accuracy: 0.9731 - val_loss: 0.2048\n",
            "Epoch 16/16\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 196ms/step - accuracy: 1.0000 - loss: 1.9748e-04 - val_accuracy: 0.9731 - val_loss: 0.2286\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9864 - loss: 0.0664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Accuracy results\n",
        "print(f\"\\nNaive Bayes Accuracy: {nb_acc:.4f}\")\n",
        "print(f\"Logistic Regression Accuracy: {lr_acc:.4f}\")\n",
        "print(f\"SVM Accuracy: {svm_acc:.4f}\")\n",
        "print(f\"LSTM Accuracy: {lstm_acc:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBIH4ojDlH8B",
        "outputId": "40f8ec49-8a6c-4827-a6c3-43533fe75430"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Naive Bayes Accuracy: 0.9740\n",
            "Logistic Regression Accuracy: 0.9570\n",
            "SVM Accuracy: 0.9821\n",
            "LSTM Accuracy: 0.9821\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(\"Naive Bayes:\\n\", classification_report(y_test, y_pred_nb))\n",
        "print(\"Logistic Regression:\\n\", classification_report(y_test, y_pred_lr))\n",
        "print(\"SVM:\\n\", classification_report(y_test, y_pred_svm))\n",
        "print(\"LSTM:\\n\", classification_report(y_test_lstm, y_pred_lstm))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_eyKVEJkWKV",
        "outputId": "ff30f05f-82ce-4875-a22a-07cd8cbd163a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.99       965\n",
            "           1       1.00      0.81      0.89       150\n",
            "\n",
            "    accuracy                           0.97      1115\n",
            "   macro avg       0.99      0.90      0.94      1115\n",
            "weighted avg       0.97      0.97      0.97      1115\n",
            "\n",
            "Logistic Regression:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98       965\n",
            "           1       0.97      0.70      0.81       150\n",
            "\n",
            "    accuracy                           0.96      1115\n",
            "   macro avg       0.96      0.85      0.89      1115\n",
            "weighted avg       0.96      0.96      0.95      1115\n",
            "\n",
            "SVM:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       965\n",
            "           1       0.99      0.88      0.93       150\n",
            "\n",
            "    accuracy                           0.98      1115\n",
            "   macro avg       0.98      0.94      0.96      1115\n",
            "weighted avg       0.98      0.98      0.98      1115\n",
            "\n",
            "LSTM:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       965\n",
            "           1       0.99      0.87      0.93       150\n",
            "\n",
            "    accuracy                           0.98      1115\n",
            "   macro avg       0.99      0.93      0.96      1115\n",
            "weighted avg       0.98      0.98      0.98      1115\n",
            "\n"
          ]
        }
      ]
    }
  ]
}